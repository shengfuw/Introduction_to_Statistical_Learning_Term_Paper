filter(character_n > 1)
## Creat document per row dataframe
document_data <- df_combined %>%
group_by(speaker_meeting) %>%
summarise(speech_text_raw = toString(speech_text_raw),
speech_text = toString(speech_text))
## Doucument level 1: each speech
speech_word_counts <- unnest_df %>%
count(speech_id, word, sort = TRUE) %>%
ungroup()
speech_dtm <- speech_word_counts %>%
arrange(speech_id) %>%
cast_dtm(speech_id, word, n)
## Doucument level 2: each speaker-meeting combination
speaker_meeting_word_counts <- unnest_df %>%
count(speaker_meeting, word, sort = TRUE) %>%
ungroup()
View(df_combined)
speaker_meeting_dtm <- speaker_meeting_word_counts %>%
arrange(speaker_meeting) %>%
cast_dtm(speaker_meeting, word, n)
metadata <- df_combined %>%
filter(speaker_meeting %in%
speaker_meeting_word_counts$speaker_meeting) %>%
group_by(speaker_meeting) %>%
summarise(speaker = first(speaker),
term = first(term),
sessionPeriod = first(sessionPeriod),
meetingDate = first(meetingDate),
days = first(days),
agendaType = first(agendaType),
gender = first(gender),
type = first(type),
party = first(party),
partyGroup = first(partyGroup),
ruling_party = first(ruling_party),
committee = committee[1]) %>% # 如果同時有兩個委員會，該如何處理？
arrange(speaker_meeting)
processed <- readCorpus(speaker_meeting_dtm, type = "dtm")
n_distinct(metadata$speaker_meeting)
length(processed$documents)
plotRemoved(processed$documents, lower.thresh = seq(1, 200, 10))
out <- prepDocuments(processed$documents,
processed$vocab, meta = metadata,
lower.thresh = 20)
docs <- out$documents
vocab <- out$vocab
meta <- out$meta
length(docs)
nrow(meta)
# meta %>% count(type)
# meta %>% filter(is.na(type))
## Doucument level 1: each speech
speech_word_counts <- unnest_df %>%
count(speech_id, word, sort = TRUE) %>%
ungroup()
speech_dtm <- speech_word_counts %>%
arrange(speech_id) %>%
cast_dtm(speech_id, word, n)
## Doucument level 2: each speaker-meeting combination
speaker_meeting_word_counts <- unnest_df %>%
count(speaker_meeting, word, sort = TRUE) %>%
ungroup()
speaker_meeting_dtm <- speaker_meeting_word_counts %>%
arrange(speaker_meeting) %>%
cast_dtm(speaker_meeting, word, n)
save(df_combined, gazette_selected, legislator, committee_info,
document_data, unnest_df, speaker_meeting_word_counts,
speaker_meeting_dtm, file = "../workdata/data_cleaned.RData")
shortdoc <- document_data %>%
filter(speaker_meeting %in% meta$speaker_meeting) %>%
mutate(short_text = substr(speech_text_raw, 1, 475))
shortdoc <- shortdoc$short_text
library(gridExtra)
library(cowplot)
myPlotQuote <- function(model, texts, topic, n = 3) {
thoughts <- findThoughts(model, texts = shortdoc, n = n,
topics = topic)$docs[[1]]
# for (i in 1:n) {
#     cat(thought[i], "\n\n")
# }
plot_list <- list()
for (i in 1:n) {
text <- strsplit(thoughts[i], "(?<=.{60})", perl = TRUE)[[1]]
text <- paste(text, collapse = "\n")
text = paste0(text, "...")
p <- ggplot(mtcars, aes(x = mpg, y = wt)) +
geom_text(aes(x = mean(range(mpg)), y = mean(range(wt))),
label = text, size = 3,
family = "jf金萱3.1 三分糖", color = "black") +
theme_void()
plot_list[[i]] <- p
}
main = paste("Topic", t)
main_title <- ggdraw() + draw_label(main, size = 14)
combined <- arrangeGrob(grobs = plot_list, ncol = 1)
final_plot <- plot_grid(main_title, combined,
ncol = 1, rel_heights = c(0.1, 0.9))
print(final_plot)
}
folder_path <- "../output/F2-4 original_document/"
if (!file.exists(folder_path)) dir.create(folder_path)
for (t in 1:20) {
png(paste0("../output/F2-4 original_document/F2-4 original_document",
t, ".png"),
width = 2680, height = 1880, res = 350)
myPlotQuote(stm20.fit, docs, t)
dev.off()
}
load("../workdata/stm_fit.rData")
labelTopics(stm15.fit)
labelTopics(stm20.fit)
# K = 15
png("../output/F2-1 stm_15.png", width = 3180, height = 1880, res = 425)
par(bty = "n", col = "grey10", lwd = 5)
plot.STM(stm15.fit, family = "jf金萱3.1 半糖",
labeltype = "frex", text.cex = .6, n = 8,
main = "Top topic (K = 15)")
dev.off()
# K = 20, frex
png("../output/F2-2 stm_20_frex.png", width = 3280, height = 2080, res = 400)
par(bty = "n", col = "grey10", lwd = 5)
plot.STM(stm20.fit, family = "jf金萱3.1 半糖", xlim = c(0, .21),
labeltype = "frex", text.cex = .7, n = 8,
main = "Top topic (K = 20)")
dev.off()
# K = 20, prob
png("../output/F2-2 stm_20_prob.png", width = 3280, height = 2080, res = 400)
par(bty = "n", col = "grey10", lwd = 5)
plot.STM(stm20.fit, family = "jf金萱3.1 半糖", xlim = c(0, .21),
text.cex = .7, n = 8,
main = "Top topic (K = 20)")
dev.off()
# K = 20, prob, with content covariate
plot.STM(stm20_gender.fit, family = "jf金萱3.1 半糖", xlim = c(0, .22),
text.cex = .7, n = 8,
main = "Top topic (K = 20)")
load("../workdata/search_for_k.rData")
## Diagnosis PLot
png("../output/F1-1 diagnosis.png", width = 2680, height = 1880, res = 400)
plot(storage)
dev.off()
exclusivity <- storage$results$exclus %>% unlist()
coherence <- storage$results$semcoh %>% unlist()
k <- paste0("K=", storage$results$K %>% unlist())
## Plot Model Seacrh for k
library("ggrepel")
ggplot()  +
geom_point(aes(coherence, exclusivity, color = k), size = 2.75) +
geom_text_repel(aes(coherence, exclusivity, label = k), fontface = "bold",
nudge_x = .25, nudge_y = -.005, size = 3, alpha = .8) +
labs(x = 'Semantic Coherence', y = 'Exclusivity') +
theme_light() +
theme(axis.title.x = element_text(face = "bold"),
axis.title.y = element_text(face = "bold"),
legend.position = "none")
ggsave("../output/F1-2 search_k.png")
write_csv(as.data.frame(storage$results), "../output/search_k_table.csv")
stm15.fit <- stm(documents = out$documents, vocab = out$vocab, K = 15,
prevalence = ~ type + party + gender + s(sessionPeriod),
max.em.its = 75, data = out$meta,
init.type = "Spectral", verbose = F, seed = 321)
load("../workdata/stm_fit.rData")
labelTopics(stm15.fit)
labelTopics(stm20.fit)
# K = 15
png("../output/F2-1 stm_15.png", width = 3180, height = 1880, res = 425)
par(bty = "n", col = "grey10", lwd = 5)
plot.STM(stm15.fit, family = "jf金萱3.1 半糖",
labeltype = "frex", text.cex = .6, n = 8,
main = "Top topic (K = 15)")
dev.off()
# K = 20, frex
png("../output/F2-2 stm_20_frex.png", width = 3280, height = 2080, res = 400)
par(bty = "n", col = "grey10", lwd = 5)
plot.STM(stm20.fit, family = "jf金萱3.1 半糖", xlim = c(0, .21),
labeltype = "frex", text.cex = .7, n = 8,
main = "Top topic (K = 20)")
dev.off()
# K = 20, prob
png("../output/F2-2 stm_20_prob.png", width = 3280, height = 2080, res = 400)
par(bty = "n", col = "grey10", lwd = 5)
plot.STM(stm20.fit, family = "jf金萱3.1 半糖", xlim = c(0, .21),
text.cex = .7, n = 8,
main = "Top topic (K = 20)")
dev.off()
# K = 20, prob, with content covariate
plot.STM(stm20_gender.fit, family = "jf金萱3.1 半糖", xlim = c(0, .22),
text.cex = .7, n = 8,
main = "Top topic (K = 20)")
folder_path <- "../output/F2-3 stm_20_cloud"
if (!file.exists(folder_path)) dir.create(folder_path)
library(RColorBrewer)
for (t in 1:20) {
png(paste0("../output/F2-3 stm_20_cloud/F2-3 stm_20_cloud_topic", t, ".png"),
width = 1280, height = 1280, res = 380)
cloud(stm20.fit, topic = 9,
min.freq = 5,
max.words = 200,
random.order = FALSE,
rot.per = 0,
colors = brewer.pal(8, "Dark2"),
family = "jf金萱3.1 三分糖")
dev.off()
}
shortdoc <- document_data %>%
filter(speaker_meeting %in% meta$speaker_meeting) %>%
mutate(short_text = substr(speech_text_raw, 1, 475))
shortdoc <- shortdoc$short_text
library(gridExtra)
library(cowplot)
myPlotQuote <- function(model, texts, topic, n = 3) {
thoughts <- findThoughts(model, texts = shortdoc, n = n,
topics = topic)$docs[[1]]
# for (i in 1:n) {
#     cat(thought[i], "\n\n")
# }
plot_list <- list()
for (i in 1:n) {
text <- strsplit(thoughts[i], "(?<=.{60})", perl = TRUE)[[1]]
text <- paste(text, collapse = "\n")
text = paste0(text, "...")
p <- ggplot(mtcars, aes(x = mpg, y = wt)) +
geom_text(aes(x = mean(range(mpg)), y = mean(range(wt))),
label = text, size = 3,
family = "jf金萱3.1 三分糖", color = "black") +
theme_void()
plot_list[[i]] <- p
}
main = paste("Topic", t)
main_title <- ggdraw() + draw_label(main, size = 14)
combined <- arrangeGrob(grobs = plot_list, ncol = 1)
final_plot <- plot_grid(main_title, combined,
ncol = 1, rel_heights = c(0.1, 0.9))
print(final_plot)
}
folder_path <- "../output/F2-4 original_document/"
if (!file.exists(folder_path)) dir.create(folder_path)
for (t in 1:20) {
png(paste0("../output/F2-4 original_document/F2-4 original_document",
t, ".png"),
width = 2680, height = 1880, res = 350)
myPlotQuote(stm20.fit, docs, t)
dev.off()
}
findThoughts(model, texts = shortdoc, n = n, topics = 1)$docs[[1]]
findThoughts(stm20.fit, texts = shortdoc, n = n, topics = 1)$docs[[1]]
findThoughts(stm20.fit, texts = shortdoc, n = n, topics = 1)$docs
View(df_combined)
View(document_data)
View(meta)
View(df_combined)
df_combined %>%
fitler(duplicated(subject)) %>% View
df_combined %>%
filter(duplicated(subject)) %>% View
gazette_selected %>%
filter(duplicated(subject)) %>% View
gazette_selected %>%
filter(duplicated(subject, meetingDate)) %>% View
df_combined %>%
filter(duplicated(speech_text_raw)) %>% View
df_combined %>%
filter(duplicated(speaker_meeting, speech_text_raw)) %>% View
gazette_selected %>%
filter(duplicated(subject) & duplicated(meetingDate)) %>% View
df_combined %>%
filter(duplicated(speaker_meeting) & duplicated(speech_text_raw)) %>% View
df_combined %>%
filter(duplicated(speaker) & duplicated(speech_text_raw)) %>% View
gazette_selected %>%
filter(duplicated(subject) & duplicated(meetingDate)) %>% View
View(gazette_selected)
duplicated_gazette_selected <- gazette_selected %>%
filter(duplicated(subject) & duplicated(meetingDate))
View(duplicated_gazette_selected)
## Merge speech data wih gazette, legislator, and committee data
df_combined <- df_combined %>%
right_join(gazette_selected, by = "meeting_id") %>% View
duplicated_gazette <- gazette_selected %>%
filter(duplicated(subject) & duplicated(meetingDate))
## 1. Gazette Info.
gazette_selected <- read_csv("../workdata/公報_selected.csv")
# Convert meeting date
gazette_selected <- gazette_selected %>%
mutate(meetingDate = as.character(19110000 + meetingDate),
meetingDate = as.Date(meetingDate, format = "%Y%m%d"))
gazette_selected$days <- as.numeric(gazette_selected$meetingDate -
min(gazette_selected$meetingDate))
duplicated_gazette <- gazette_selected %>%
filter(duplicated(subject) & duplicated(meetingDate))
## 2. Legislators Info.
legislator_raw <- read_csv("../rawdata/當屆委員資料.csv")
legislator <- legislator_raw %>%
mutate(name = str_replace_all(name, "[^\u4e00-\u9fff]", ""),
gender = as.factor(sex),
gender = ifelse(gender == "男", "Male", "Female"),
type = case_when(str_detect(areaName, "原住民") ~ "原住民",
str_detect(areaName, "全國不分區") ~ "不分區",
str_detect(areaName, "選舉區") ~ "區域",
TRUE ~ areaName),
ruling_party = ifelse(party == "民主進步黨", "Ruling", "Opposition"),
type = as.factor(type),
type_raw = as.factor(areaName)) %>%
select(name, gender, type, type_raw,
party, partyGroup, ruling_party, committee)
## 3. Committees Info.
ad_hoc_committees <- c("程序委員會", "紀律委員會", "修憲委員會",
"經費稽核委員會", "調閱委員會")
committee_info <- legislator %>%
select(name, committee) %>%
## Remove 特種委員會
mutate(committee = str_remove_all(committee,
paste(ad_hoc_committees, collapse = "|")),
committee = str_replace_all(committee,
"第(\\d)+屆第(\\d)+會期：;", ""))
get_committee <- function(text, s) {
pattern = paste0("第(\\d)+屆第", s, "會期：(.+?);")
reuslt = str_extract_all(text, pattern) %>%
str_extract_all("：(.*?);") %>%
unlist() %>%
str_remove_all("[：;]")
if (length(reuslt) == 0)
return(NA)
else
return(reuslt)
}
committee_info <- committee_info %>%
mutate(session1 = map(committee, ~ get_committee(., 1)),
session2 = map(committee, ~ get_committee(., 2)),
session3 = map(committee, ~ get_committee(., 3)),
session4 = map(committee, ~ get_committee(., 4)),
session5 = map(committee, ~ get_committee(., 5)),
session6 = map(committee, ~ get_committee(., 6)),
session7 = map(committee, ~ get_committee(., 7)))
committee_info <- committee_info %>%
select(-committee) %>%
pivot_longer(cols = starts_with("session"),
names_to = "sessionPeriod",
values_to = "committee") %>%
mutate(sessionPeriod = str_replace(sessionPeriod, "session", ""),
sessionPeriod = as.numeric(sessionPeriod)) %>%
rename(speaker = name)
library(readxl)
library(tidyverse)
library(tidytext)
library(wordcloud2)
library(jiebaR)
library(tm)
library(topicmodels)
library(stm)
library(stminsights)
setwd("/Users/Shengfu/Desktop/臺大/統計學習理論簡介 曾煥凱/Final Project/Analysis/do")
list.files()
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(readxl)
library(tidyverse)
library(tidytext)
library(wordcloud2)
library(jiebaR)
library(tm)
library(topicmodels)
library(stm)
library(stminsights)
setwd("/Users/Shengfu/Desktop/臺大/統計學習理論簡介 曾煥凱/Final Project/Analysis/do")
list.files()
rm(list = ls())
## 1. Gazette Info.
gazette_selected <- read_csv("../workdata/公報_selected.csv")
# Convert meeting date
gazette_selected <- gazette_selected %>%
mutate(meetingDate = as.character(19110000 + meetingDate),
meetingDate = as.Date(meetingDate, format = "%Y%m%d"))
gazette_selected$days <- as.numeric(gazette_selected$meetingDate -
min(gazette_selected$meetingDate))
duplicated_gazette <- gazette_selected %>%
filter(duplicated(subject) & duplicated(meetingDate))
## 2. Legislators Info.
legislator_raw <- read_csv("../rawdata/當屆委員資料.csv")
legislator <- legislator_raw %>%
mutate(name = str_replace_all(name, "[^\u4e00-\u9fff]", ""),
gender = as.factor(sex),
gender = ifelse(gender == "男", "Male", "Female"),
type = case_when(str_detect(areaName, "原住民") ~ "原住民",
str_detect(areaName, "全國不分區") ~ "不分區",
str_detect(areaName, "選舉區") ~ "區域",
TRUE ~ areaName),
ruling_party = ifelse(party == "民主進步黨", "Ruling", "Opposition"),
type = as.factor(type),
type_raw = as.factor(areaName)) %>%
select(name, gender, type, type_raw,
party, partyGroup, ruling_party, committee)
## 3. Committees Info.
ad_hoc_committees <- c("程序委員會", "紀律委員會", "修憲委員會",
"經費稽核委員會", "調閱委員會")
committee_info <- legislator %>%
select(name, committee) %>%
## Remove 特種委員會
mutate(committee = str_remove_all(committee,
paste(ad_hoc_committees, collapse = "|")),
committee = str_replace_all(committee,
"第(\\d)+屆第(\\d)+會期：;", ""))
get_committee <- function(text, s) {
pattern = paste0("第(\\d)+屆第", s, "會期：(.+?);")
reuslt = str_extract_all(text, pattern) %>%
str_extract_all("：(.*?);") %>%
unlist() %>%
str_remove_all("[：;]")
if (length(reuslt) == 0)
return(NA)
else
return(reuslt)
}
committee_info <- committee_info %>%
mutate(session1 = map(committee, ~ get_committee(., 1)),
session2 = map(committee, ~ get_committee(., 2)),
session3 = map(committee, ~ get_committee(., 3)),
session4 = map(committee, ~ get_committee(., 4)),
session5 = map(committee, ~ get_committee(., 5)),
session6 = map(committee, ~ get_committee(., 6)),
session7 = map(committee, ~ get_committee(., 7)))
committee_info <- committee_info %>%
select(-committee) %>%
pivot_longer(cols = starts_with("session"),
names_to = "sessionPeriod",
values_to = "committee") %>%
mutate(sessionPeriod = str_replace(sessionPeriod, "session", ""),
sessionPeriod = as.numeric(sessionPeriod)) %>%
rename(speaker = name)
# Set the directory path
directory <- "../workdata/speech"
## Get a list of file names in the directory
file_list <- list.files(directory, pattern = "\\.csv$", full.names = TRUE)
## Initialize an empty list to store the data frames
df_list <- list()
## Iterate over the file list and read each CSV file
for (file in file_list) {
data <- read_csv(file)
df_list[[file]] <- data
}
rm(data)
## Combine into one dataframe
df_combined <- do.call(rbind, df_list)
row.names(df_combined) <- NULL
rm(df_list)
## Merge committee df to legislator df
legislator_long <- legislator %>%
rename(speaker = name) %>%
left_join(committee_info, by = "speaker") %>%
select(-committee.x) %>%
rename(committee = committee.y)
## Name change or typo
df_combined <- df_combined %>%
mutate(speaker = str_replace(speaker, "洪申瀚", "洪申翰"),
speaker = str_replace(speaker, "葉毓蘭", "游毓蘭"),
speaker = str_replace(speaker, "蔣萬中", "蔣萬安"))
# Create id for each speaker_meeting and speech
df_combined <- df_combined %>%
mutate(speaker_meeting = str_c(speaker, meeting_id, sep = "_"),
speech_id = str_c(meeting_id, speech_number, sep = "_"))
## Merge speech data wih gazette, legislator, and committee data
df_combined <- df_combined %>%
right_join(gazette_selected, by = "meeting_id") %>%
anti_join(duplicated_gazette, by = "meeting_id") %>%
left_join(legislator_long, by = c("speaker", "sessionPeriod")) %>%
select(meeting_id, speaker, speech_number, speaker_meeting, speech_id, speech_text, term, sessionPeriod, comYear, comVolume, comBookId, meetingDate, days, agendaNo, agendaType, subject, pageStart, pageEnd, gender, type, type_raw, party, partyGroup, ruling_party,  committee)
n_distinct(df_combined$meeting_id) # Number of meeting
n_distinct(df_combined$speaker_meeting) # Number of speaker_meeting
## Remove numbers, punctuation(, English characters)
df_combined <- df_combined %>%
mutate(speech_text_raw = speech_text,
speech_text = gsub("[[:punct:]]", " ", speech_text),
speech_text = gsub("http\\w+", " ", speech_text),
# speech_text = gsub("[a-zA-Z]", " ", speech_text))
speech_text = gsub("[0-9]", " ", speech_text),
speech_text = gsub("//", " ", speech_text),
speech_text = gsub("/", " ", speech_text),
speech_text = tolower(speech_text))
## Using jiebaR to 中文斷詞
stop = "./my_dictionary/stop_zhtw.txt"
user = "./my_dictionary/taiwan_zhtw.txt"
cutter <- worker(bylines = TRUE, stop_word = stop, user = user)
cutter_mix <- worker(type = "mix", bylines = TRUE, stop_word = stop, user = user)
unnest_df <- df_combined %>%
mutate(text = sapply(segment(speech_text, cutter_mix),
function(x){paste(x, collapse = " ")})) %>%
unnest_tokens(word, text, token = "regex", pattern = " " , drop = F) %>%
mutate(character_n = nchar(word)) %>%
filter(character_n > 1)
## Creat document per row dataframe
document_data <- df_combined %>%
group_by(speaker_meeting) %>%
summarise(speech_text_raw = toString(speech_text_raw),
speech_text = toString(speech_text))
## Doucument level 1: each speech
speech_word_counts <- unnest_df %>%
count(speech_id, word, sort = TRUE) %>%
ungroup()
speech_dtm <- speech_word_counts %>%
arrange(speech_id) %>%
cast_dtm(speech_id, word, n)
## Doucument level 2: each speaker-meeting combination
speaker_meeting_word_counts <- unnest_df %>%
count(speaker_meeting, word, sort = TRUE) %>%
ungroup()
speaker_meeting_dtm <- speaker_meeting_word_counts %>%
arrange(speaker_meeting) %>%
cast_dtm(speaker_meeting, word, n)
save(df_combined, gazette_selected, legislator, committee_info,
document_data, unnest_df, speaker_meeting_word_counts,
speaker_meeting_dtm, file = "../workdata/data_cleaned.RData")
